{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+PK2wBtU82hZjow23+qdy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaratNaz12/ML-DL/blob/main/cifar10_class_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import and data preparation"
      ],
      "metadata": {
        "id": "wV_6zofO_87B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UzU_7Irwr311"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import torch\n",
        "import torchvision\n",
        "import tarfile\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import optimizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
        "download_url(dataset_url, '.')\n",
        "with tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n",
        "    tar.extractall(path='./data')\n",
        "data_dir = './data/cifar10'\n",
        "dataset = ImageFolder(data_dir + '/train',transform = ToTensor())\n",
        "valid_size = 5000\n",
        "train_size = len(dataset) - valid_size\n",
        "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
        "batch_size = 128\n",
        "train_dataset_load = DataLoader(train_dataset, batch_size, shuffle = True, num_workers = 2, pin_memory = True)\n",
        "\n",
        "valid_dataset_load = DataLoader(valid_dataset, batch_size * 2, num_workers = 2, pin_memory = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCAubV_xsFqW",
        "outputId": "2ffe8d29-bb94-41f5-8bce-52607500edfb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: ./cifar10.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NN Model"
      ],
      "metadata": {
        "id": "q6h8xE-X_g-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs,labels):\n",
        "  _,preds = torch.max(outputs,dim = 1)\n",
        "  return torch.tensor(torch.sum(preds == labels).item()/len(preds))\n",
        "  "
      ],
      "metadata": {
        "id": "7_-uH1X_Ms3e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageClasificationBase(nn.Module):\n",
        "\n",
        "  def training_step(self,batch):\n",
        "    images,labels = batch\n",
        "    out = self(images)\n",
        "    loss = F.cross_entropy(out,labels)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self,batch):\n",
        "    images,labels = batch\n",
        "    out = self(images)\n",
        "    loss = F.cross_entropy(out,labels)\n",
        "    acc = accuracy(out,labels)\n",
        "    return {'val_loss':loss.detach(),'val_acc': acc}\n",
        "\n",
        "  def validation_epoch_end(self,outputs):\n",
        "    batch_losses = [x['val_loss'] for x in outputs]\n",
        "    epoch_loss = torch.tensor(batch_losses).mean()\n",
        "    batch_accs = [x['val_acc'] for x in outputs]\n",
        "    epoch_acc = torch.tensor(batch_accs).mean()\n",
        "    return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "  \n",
        "  def epoch_end(self,epoch,result):\n",
        "     print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['val_loss'], result['val_acc']))\n",
        "     "
      ],
      "metadata": {
        "id": "NT3KoIDz6QIV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class probCNNModel(ImageClasificationBase):\n",
        "  def __init__(self):\n",
        "    super().__init__()  \n",
        "    self.network = nn.Sequential(\n",
        "        \n",
        "        nn.Conv2d(3,32, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2),# output: 64 x 16 x 16\n",
        "\n",
        "        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
        "\n",
        "        nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
        "\n",
        "        nn.Flatten(), \n",
        "        nn.Linear(256*4*4, 1024),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(1024, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10)\n",
        "    )\n",
        "  def forward(self, xb):\n",
        "    return self.network(xb)\n",
        "model = probCNNModel()"
      ],
      "metadata": {
        "id": "KXqQ0vHnNn-b"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "UGevqtpt_lqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate(model,valid_dataset_load):\n",
        "  model.eval()\n",
        "  outputs = [model.validation_step(batch) for batch in valid_dataset_load]\n",
        "  return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs_num, lr, model, train_dataset_load, valid_dataset_load, opt_func = torch.optim.SGD):\n",
        "  history= []\n",
        "  train_losses = []\n",
        "  opt = opt_func(model.parameters(), lr)\n",
        "  for epoch in range(epochs_num):\n",
        "    model.train()\n",
        "    for batch in train_dataset_load:\n",
        "      loss = model.training_step(batch)\n",
        "      train_losses.append(loss)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "\n",
        "    result = evaluate(model,valid_dataset_load)\n",
        "    result['val_loss'] = torch.tensor(train_losses).mean().item()\n",
        "    history.append(result)\n",
        "    model.epoch_end(epoch,result)\n",
        "  return history\n",
        "\n"
      ],
      "metadata": {
        "id": "udhUxiE-Peer"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###GPU activvation"
      ],
      "metadata": {
        "id": "ESsRNziS_rCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "train_dataset_load = DeviceDataLoader(train_dataset_load, get_default_device())\n",
        "valid_dataset_load = DeviceDataLoader(valid_dataset_load, get_default_device())\n",
        "to_device(model, get_default_device());\n",
        "model = to_device(probCNNModel(), get_default_device())"
      ],
      "metadata": {
        "id": "6DmSFYW9xIh2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### T&T"
      ],
      "metadata": {
        "id": "Ap1yGVg9_159"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_num = 10\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.001\n",
        "history = fit(epochs_num, lr, model, train_dataset_load, valid_dataset_load, opt_func)"
      ],
      "metadata": {
        "id": "YzCLpO76YfeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "matplotlib.rcParams['figure.facecolor'] = '#ffffff'"
      ],
      "metadata": {
        "id": "xrM1Qg_g3-6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "plot_accuracies(history)"
      ],
      "metadata": {
        "id": "QvC9rz2f4Bfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(history):\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('val_loss')\n",
        "    plt.title('Loss vs. No. of epochs')\n",
        "plot_losses(history)"
      ],
      "metadata": {
        "id": "3-spe--b4WsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = ImageFolder(data_dir + '/test',transform = ToTensor())\n",
        "# def predict_image(img,model):\n",
        "#   img = to_device(img.unsqueeze(0), get_default_device())\n",
        "#   pred = model(img)\n",
        "#   _,pred = torch.max(pred, dim = 1)\n",
        "#   return dataset.classes[pred[0].item()]\n",
        "# img,label = dataset[114]\n",
        "# plt.imshow(img.permute(1,2,0))\n",
        "# print(\"Label\", dataset.classes[label],'pred', predict_image(img,model))"
      ],
      "metadata": {
        "id": "_JUB6Hzd46KQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}